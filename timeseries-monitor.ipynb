{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3320de55-85f4-4179-9904-5b0df7c88f15",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Lakehouse monitoring example notebook: TimeSeries analysis\n",
    "\n",
    "**User requirements**\n",
    "- You must have access to run commands on a cluster with access to Unity Catalog.\n",
    "- You must have `USE CATALOG` privilege on at least one catalog, and you must have `USE SCHEMA` privileges on at least one schema. This notebook creates tables in the `main.default` schema. If you do not have the required privileges on the `main.default` schema, you must edit the notebook to change the default catalog and schema to ones that you do have privileges on.\n",
    "\n",
    "**System requirements:**\n",
    "- Your workspace must be enabled for Unity Catalog.\n",
    "- Databricks Runtime 12.2LTS or above.\n",
    "- A Single user or Assigned cluster.\n",
    "\n",
    "This notebook illustrates how to create a time series monitor.\n",
    "\n",
    "For more information about Lakehouse monitoring, see the documentation ([AWS](https://docs.databricks.com/lakehouse-monitoring/index.html)|[Azure](https://learn.microsoft.com/azure/databricks/lakehouse-monitoring/index))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0413680e-52ad-4625-816c-877c2aa5dc47",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Setup\n",
    "* Verify cluster configuration\n",
    "* Install Python client\n",
    "* Define catalog, schema and table names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5dcbfddb-0bed-49e3-9f42-5182499c3920",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check the cluster configuration. If this cell fails, use the cluster selector at the top right of the notebook to select or configure a cluster running Databricks Runtime 12.2 LTS or above.\n",
    "import os\n",
    "\n",
    "assert float(os.environ.get(\"DATABRICKS_RUNTIME_VERSION\", 0)) >= 12.2, \"Please configure your cluster to use Databricks Runtime 12.2 LTS or above.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29931351-1cad-4913-a9b4-cb602c213999",
     "showTitle": true,
     "title": "Install Lakehouse Monitoring client wheel"
    }
   },
   "outputs": [],
   "source": [
    "%pip install \"https://ml-team-public-read.s3.amazonaws.com/wheels/data-monitoring/a4050ef7-b183-47a1-a145-e614628e3146/databricks_lakehouse_monitoring-0.4.14-py3-none-any.whl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bee99dce-180e-4780-b6d4-f4e1f0be0af9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This step is necessary to reset the environment with our newly installed wheel.\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b56c4a9-753c-4047-ab69-837e8bdb0bdb",
     "showTitle": true,
     "title": "Specify catalog and schema to use"
    }
   },
   "outputs": [],
   "source": [
    "# You must have `USE CATALOG` privileges on the catalog, and you must have `USE SCHEMA` privileges on the schema.\n",
    "# If necessary, change the catalog and schema name here.\n",
    "\n",
    "CATALOG = \"main\"\n",
    "SCHEMA = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4d5d795-9104-4039-824a-2709fa149d38",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "username = spark.sql(\"SELECT current_user()\").first()[\"current_user()\"]\n",
    "username_prefixes = username.split(\"@\")[0].split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65bc2cef-7f1a-46a5-be61-488aa0f741e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "unique_suffix = \"_\".join([username_prefixes[0], username_prefixes[1][0:2]])\n",
    "TABLE_NAME = f\"{CATALOG}.{SCHEMA}.wine_ts_{unique_suffix}\"\n",
    "BASELINE_TABLE = f\"{CATALOG}.{SCHEMA}.wine_ts_baseline_{unique_suffix}\"\n",
    "TIMESTAMP_COL = \"timestamp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a00353b0-c176-41b8-a65f-5ab22a871696",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"DROP TABLE IF EXISTS {TABLE_NAME}\")\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {BASELINE_TABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3c7f8c5-30a1-46fd-9d26-d85c305735c4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## User Journey\n",
    "1. Create tables: Read raw data and create the primary table (the table to be monitored) and the baseline table (which contains data known to meet expected quality standards).\n",
    "2. Create a monitor on the primary table.\n",
    "3. Inspect the metrics tables.\n",
    "4. Apply changes to table and refresh metrics. Inspect the metrics tables.\n",
    "5. [Optional] Delete the monitor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ef2917e-8cf0-4a9e-92bd-9972c8962c09",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Create the primary and (optional) baseline tables in Unity Catalog\n",
    "* The tables must be Delta tables registered in Unity Catalog and owned by the user running the notebook.  \n",
    "* The table to be monitored is also called the \"primary table\".  \n",
    "* The baseline table must have the same schema as the monitored table.\n",
    "\n",
    "This example uses the `winequality` datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a9b749c-c505-4097-9fa7-99b89e851318",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "white_wine = pd.read_csv(\"/dbfs/databricks-datasets/wine-quality/winequality-white.csv\", sep=\";\")\n",
    "red_wine = pd.read_csv(\"/dbfs/databricks-datasets/wine-quality/winequality-red.csv\", sep=\";\")\n",
    "\n",
    "# Add categoricals\n",
    "white_wine[\"type\"] = \"white\"\n",
    "red_wine[\"type\"] = \"red\"\n",
    "data_pdf = pd.concat([white_wine, red_wine], axis=0)\n",
    "\n",
    "# Clean columns\n",
    "data_pdf.columns = data_pdf.columns.str.replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8bcb22f-185e-46ff-9155-9411936bca0a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Split the data. `baseline_df` is the baseline table, `ts1_df` is the primary table, and `ts2_df` is used to simulate future data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d11eac92-4603-4219-a6fa-253f721ff4fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_df = spark.createDataFrame(data_pdf)\n",
    "baseline_df, ts1_df, ts2_df = data_df.randomSplit(weights=[0.20, 0.40, 0.40], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ccf710de-b919-4fda-a893-32e9d6f54d7e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Create different timestamps to simulate timeseries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce82b174-e847-4546-a85d-35f2b43e5728",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta, datetime\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5227e9bc-09e0-4c54-85f8-8dc19069a4a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Simulate data with different timestamps\n",
    "timestamp_0 = datetime.now() # Baseline data\n",
    "timestamp_1 = (datetime.now() + timedelta(1)).timestamp() # 1 day later\n",
    "timestamp_2 = (datetime.now() + timedelta(2)).timestamp() \n",
    "\n",
    "baseline_df = baseline_df.withColumn(\"timestamp\", F.lit(timestamp_0).cast(\"timestamp\"))\n",
    "ts1_df = ts1_df.withColumn(\"timestamp\", F.lit(timestamp_1).cast(\"timestamp\"))\n",
    "ts2_df = ts1_df.withColumn(\"timestamp\", F.lit(timestamp_2).cast(\"timestamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1444793e-609e-4631-9731-0d00dc09fb34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "baseline_df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38c3a241-79c0-48d0-8b2b-2757e8c7ff49",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Create the baseline and primary Delta tables in Unity Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf55fe82-0be3-42d8-918e-1e5d8f830193",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write the baseline table to Unity Catalog\n",
    "\n",
    "(baseline_df\n",
    "  .write\n",
    "  .format(\"delta\")\n",
    "  .mode(\"overwrite\")\n",
    "  .option(\"overwriteSchema\",True)\n",
    "  .option(\"delta.enableChangeDataFeed\", \"true\")\n",
    "  .saveAsTable(f\"{BASELINE_TABLE}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5907e26-1780-416c-b2eb-d13d92510d60",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write the primary table to Unity Catalog. This is the table to be monitored. Later in this notebook, we will add data for future timestamps to this table. \n",
    "\n",
    "(ts1_df\n",
    "  .write\n",
    "  .format(\"delta\")\n",
    "  .mode(\"overwrite\")\n",
    "  .option(\"overwriteSchema\",True)\n",
    "  .option(\"delta.enableChangeDataFeed\", \"true\")\n",
    "  .saveAsTable(f\"{TABLE_NAME}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1403887b-f4df-4fe6-94d3-b825ee82f4ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"SELECT COUNT(*) FROM {TABLE_NAME}\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "270812cf-4bfc-45e6-9551-99eb95f66cff",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2. Create the monitor\n",
    "This notebook illustrates `TimeSeries` type analysis. For other types of analysis, see the Lakehouse Monitoring documentation ([AWS](https://docs.databricks.com/lakehouse-monitoring/index.html)|[Azure](https://learn.microsoft.com/azure/databricks/lakehouse-monitoring/index)).\n",
    "\n",
    "**Make sure to drop any columns that should be excluded from a business or use-case perspective.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2488872c-9499-458f-b10d-4d8d100b0cd6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import databricks.lakehouse_monitoring as lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47aded4e-7a03-4a1c-8e4b-10e72ed98211",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Window sizes to analyze data over\n",
    "GRANULARITIES = [\"1 day\"]                       \n",
    "\n",
    "# Expressions to slice data with\n",
    "SLICING_EXPRS = [\"type='Red'\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8bcaf298-cf3c-4096-91df-3254c1886469",
     "showTitle": true,
     "title": "Create Monitor"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Creating monitor for {TABLE_NAME}\")\n",
    "\n",
    "info = lm.create_monitor(\n",
    "  table_name=TABLE_NAME,\n",
    "  profile_type=lm.TimeSeries(\n",
    "    timestamp_col=TIMESTAMP_COL,\n",
    "    granularities=GRANULARITIES\n",
    "  ),\n",
    "  slicing_exprs=SLICING_EXPRS,\n",
    "  baseline_table_name=BASELINE_TABLE,\n",
    "  output_schema_name=f\"{CATALOG}.{SCHEMA}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1adff894-e31f-4add-8082-9082ca52a49a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "# Wait for monitor to be created\n",
    "while info.status == lm.MonitorStatus.PENDING:\n",
    "  info = lm.get_monitor(table_name=TABLE_NAME)\n",
    "  time.sleep(10)\n",
    "\n",
    "assert(info.status == lm.MonitorStatus.ACTIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a93cf7a-bfcd-44fd-b48f-26e8631beaab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# A metric refresh will automatically be triggered on creation\n",
    "refreshes = lm.list_refreshes(table_name=TABLE_NAME)\n",
    "assert(len(refreshes) > 0)\n",
    "\n",
    "run_info = refreshes[0]\n",
    "while run_info.state in (lm.RefreshState.PENDING, lm.RefreshState.RUNNING):\n",
    "  run_info = lm.get_refresh(table_name=TABLE_NAME, refresh_id=run_info.refresh_id)\n",
    "  time.sleep(30)\n",
    "\n",
    "assert(run_info.state == lm.RefreshState.SUCCESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61ad4006-695b-41ad-965a-2d5e635b2e82",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Click the highlighted Dashboard link in the cell output to open the dashboard. You can also navigate to the dashboard from the Catalog Explorer UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "433fe9e4-4702-4944-acee-64124d412565",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lm.get_monitor(table_name=TABLE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "056b8ce3-7047-4285-bb76-acbaecee70c6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3. Inspect the metrics tables\n",
    "\n",
    "By default, the metrics tables are saved in the default database.  \n",
    "\n",
    "The `create_monitor` call created two new tables: the profile metrics table and the drift metrics table. \n",
    "\n",
    "These two tables record the outputs of analysis jobs. The tables use the same name as the primary table to be monitored, with the suffixes `_profile_metrics` and `_drift_metrics`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52611b9f-a8c2-40e2-94af-e7061e4ede17",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Orientation to the profile metrics table\n",
    "\n",
    "The profile metrics table has the suffix `_profile_metrics`. For a list of statistics that are shown in the table, see the documentation ([AWS](https://docs.databricks.com/lakehouse-monitoring/monitor-output.html#profile-metrics-table)|[Azure](https://learn.microsoft.com/azure/databricks/lakehouse-monitoring/monitor-output#profile-metrics-table)). \n",
    "\n",
    "- For every column in the primary table, the profile table shows summary statistics for the baseline table and for the primary table. The column `log_type` shows `INPUT` to indicate statistics for the primary table, and `BASELINE` to indicate statistics for the baseline table. The column from the primary table is identified in the column `column_name`.\n",
    "- For `TimeSeries` type analysis, the `granularity` column shows the granularity corresponding to the row. For baseline table statistics, the `granularity` column shows `null`.\n",
    "- The table shows statistics for each value of each slice key in each time window, and for the table as whole. Statistics for the table as a whole are indicated by `slice_key` = `slice_value` = `null`.\n",
    "- In the primary table, the `window` column shows the time window corresponding to that row. For baseline table statistics, the `window` column shows `null`.  \n",
    "- Some statistics are calculated based on the table as a whole, not on a single column. In the column `column_name`, these statistics are identified by `:table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cee9c34f-0043-4fb4-afa5-ce38dd96eba6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display profile metrics table\n",
    "profile_table = f\"{TABLE_NAME}_profile_metrics\"\n",
    "display(spark.sql(f\"SELECT * FROM {profile_table}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9614680b-322b-40ec-9088-0f5761d19edf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Orientation to the drift metrics table\n",
    "\n",
    "The drift metrics table has the suffix `_drift_metrics`. For a list of statistics that are shown in the table, see the documentation ([AWS](https://docs.databricks.com/lakehouse-monitoring/monitor-output.html#drift-metrics-table)|[Azure](https://learn.microsoft.com/azure/databricks/lakehouse-monitoring/monitor-output#drift-metrics-table)). \n",
    "\n",
    "- For every column in the primary table, the drift table shows a set of metrics that compare the current values in the table to the values at the time of the previous analysis run and to the baseline table. The column `drift_type` shows `BASELINE` to indicate drift relative to the baseline table, and `CONSECUTIVE` to indicate drift relative to a previous time window. As in the profile table, the column from the primary table is identified in the column `column_name`.\n",
    "  - At this point, because this is the first run of this monitor, there is no previous window to compare to. So there are no rows where `drift_type` is `CONSECUTIVE`. \n",
    "- For `TimeSeries` type analysis, the `granularity` column shows the granularity corresponding to that row.\n",
    "- The table shows statistics for each value of each slice key in each time window, and for the table as whole. Statistics for the table as a whole are indicated by `slice_key` = `slice_value` = `null`.\n",
    "- The `window` column shows the the time window corresponding to that row. The `window_cmp` column shows the comparison window. If the comparison is to the baseline table, `window_cmp` is `null`.  \n",
    "- Some statistics are calculated based on the table as a whole, not on a single column. In the column `column_name`, these statistics are identified by `:table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c48e9a23-fecc-4957-9811-325717334cb4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display the drift metrics table\n",
    "drift_table = f\"{TABLE_NAME}_drift_metrics\"\n",
    "display(spark.sql(f\"SELECT * FROM {drift_table}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7b4b4d0-47aa-4ccd-94cc-a2e3f2b76fac",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 4. Add new data to the table and refresh metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38cddf5d-d012-47bc-b7f2-d6529623d199",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Add new data to the table\n",
    "The following cell appends the simulated future data from `ts2_df` to the primary table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "456cc141-1aaa-4f9e-a4c7-505fcf94c12f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(ts2_df\n",
    "  .write.format(\"delta\").mode(\"append\") \n",
    "  .option(\"mergeSchema\",True) \n",
    "  .option(\"delta.enableChangeDataFeed\", \"true\") \n",
    "  .saveAsTable(f\"{TABLE_NAME}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b075eb0a-9dc1-4a30-bff0-0dbbb4bae82e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"SELECT COUNT(*) FROM {TABLE_NAME}\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44bdb580-e9a2-44e0-bb91-cce6925fb1c1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Refresh metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "994d1b96-a56d-4d77-958d-f6c84b2f10f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "run_info = lm.run_refresh(table_name=TABLE_NAME)\n",
    "while run_info.state in (lm.RefreshState.PENDING, lm.RefreshState.RUNNING):\n",
    "  run_info = lm.get_refresh(table_name=TABLE_NAME, refresh_id=run_info.refresh_id)\n",
    "  time.sleep(30)\n",
    "\n",
    "assert(run_info.state == lm.RefreshState.SUCCESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1eb267b-105c-4d43-971c-721546e407bc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Open the monitoring dashboard to notice the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68bc26b4-2df3-4d41-ba85-8dec4b80131c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lm.get_monitor(table_name=TABLE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d7c487c-b946-46a9-8a3b-a115db041815",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## [Optional] Delete the monitor\n",
    "Uncomment the following line of code to clean up the monitor. Only a single monitor can exist for a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2427048-fc50-4795-a878-170e17da6f01",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# lm.delete_monitor(table_name=TABLE_NAME)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "timeseries-monitor",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
